{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the new functions to work around poor extraction quality\n",
    "\n",
    "def decision_number_html_extractor(url):\n",
    "    # Extracts the HTML with the decision numbers\n",
    "    response = requests.get(url)\n",
    "    html = BeautifulSoup(response.text, \"html.parser\")\n",
    "    details = html.find_all(\"div\", class_=\"field field--name-field-product-number field--type-string field--label-hidden field__item\")\n",
    "    return(details)\n",
    "    \n",
    "def splitter(html_output, results):\n",
    "    # Splits the decision number out of the HTML\n",
    "    html_ouput = html_output\n",
    "    \n",
    "    for i in range(0, len(html_output)):\n",
    "        output_string = str(html_ouput[i])\n",
    "        step1 = output_string.split(\">\",1)[1]\n",
    "        step2 = step1.split(\"</div>\",1)[0]\n",
    "        results.append(step2)\n",
    "    \n",
    "    return(results)\n",
    "\n",
    "def new_url_generator(base_url, decision_no):\n",
    "    # Creates a new URL with decision numbers\n",
    "    new_list = str(decision_no).split(\",\")\n",
    "    addition = \"%2C\".join(new_list).lower()\n",
    "    new_url = base_url + addition\n",
    "    return(new_url)\n",
    "\n",
    "def highlight_extractor(x):\n",
    "    # Cleans up the highlight paragraph\n",
    "    new_string = str(x)\n",
    "    first_pass = new_string.split(\"<!--HTML--><html><body><p>\", 1)[1]\n",
    "    second_pass = first_pass.split(\"</p>\\n</body></html>\\n\", 1)[0]\n",
    "    return(second_pass)\n",
    "\n",
    "def general_splitter(x, patterns):\n",
    "    new_string = str(x)\n",
    "    first_pass = new_string.split(patterns[0], 1)[1]\n",
    "    second_pass = first_pass.split(patterns[1], 1)[0]\n",
    "    return(second_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_url = \"https://www.gao.gov/search?f%5B0%5D=content_type%3ABid%20Protest%20Decision&f%5B1%5D=date%3Astart%2B2000-01-01%2Bend%2B2020-01-01&sort_by=docdate&sort_order=DESC&keyword=&f%5B0%5D=content_type%3ABid%20Protest%20Decision&f%5B1%5D=date%3Astart%2B2000-01-01%2Bend%2B2020-01-01&page=\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for p in range(0, 543):\n",
    "    new_url = recursive_url+\"p\"\n",
    "    html = decision_number_html_extractor(new_url)\n",
    "    splitter(html, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_url_input = \"https://www.gao.gov/products/\"\n",
    "\n",
    "aggregate_results = {}\n",
    "\n",
    "for d in range(0, len(results)):\n",
    "    url = new_url_generator(base_url_input, results[d])\n",
    "    response = requests.get(url)\n",
    "    html = BeautifulSoup(response.text, \"html.parser\")\n",
    "    status = html.find(\"div\", class_ = \"status highlighted-status\")\n",
    "    highlights = html.find_all(\"div\", class_ = \"clearfix text-formatted field field--name-product-highlights-custom field--type-text-long field--label-above quickedit-field\")\n",
    "    document = html.find_all(\"div\", class_ = \"js-endpoint-view-decision field field--name-field-html-block field--type-text-long field--label-above\")\n",
    "    protest_dict = {'result_no' : str(results[d]), 'status' : str(status), 'highlights' : str(highlights), \"document\": str(document)}\n",
    "    aggregate_results[d] = protest_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"aggregate_results.json\", \"w\") as fp:\n",
    "    json.dump(aggregate_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        We sustain the protest'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firm_patterns = [\"Matter of:\\xa0</strong> \", \"</p>\\n<p><strong>File:\"]\n",
    "date_patterns = [\"\\n<p><strong>Date:</strong>\\xa0 \", \"</p>\\n<div>\\n<p>\"]\n",
    "decision_paragraph_patterns = [\"<div>\\n<p>DECISION</p>\\n</div>\\n<p>\", \"</p>\"]\n",
    "status_patterns = ['<div class=\"status highlighted-status\">\\n', '.\\n      </div>']\n",
    "\n",
    "test_result = aggregate_results[0]\n",
    "\n",
    "firm = general_splitter(test_result['document'], firm_patterns)\n",
    "date = general_splitter(test_result['document'], date_patterns)\n",
    "decision_paragraph = general_splitter(test_result['document'], decision_paragraph_patterns)\n",
    "general_splitter(test_result['status'], status_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df = pd.DataFrame()\n",
    "\n",
    "for d in range(0, len(results)):\n",
    "    firm = general_splitter(aggregate_results[d]['document'], firm_patterns)\n",
    "    date = general_splitter(aggregate_results[d]['document'], date_patterns)\n",
    "    status = general_splitter(aggregate_results[d]['status'], status_patterns)\n",
    "    decision_paragraph = general_splitter(aggregate_results[d]['document'], decision_paragraph_patterns)\n",
    "    highlights = highlight_extractor(aggregate_results[d]['highlights'])\n",
    "    series = {\"Firm\" :str(firm), \"Date\" : str(date), \"Status\" : str(status), \"Decision\" : str(decision_paragraph), \"Highlights\" : str(highlights)}\n",
    "    good_df = good_df.append(series, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df.to_csv(\"output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
